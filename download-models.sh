#!/bin/bash
# LLM ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ (ë‚´ë¶€ë§ ë°˜ìž…ìš©)

set -e

echo "ðŸ¤– ë‚´ë¶€ë§ìš© LLM ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œìž‘"

# ëª¨ë¸ ì €ìž¥ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p models
cd models

# Hugging Face ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜
download_hf_model() {
    local model_name=$1
    local local_dir=$2
    
    echo "ðŸ“¥ ë‹¤ìš´ë¡œë“œ ì¤‘: $model_name -> $local_dir"
    
    python3 -c "
import os
from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM
from sentence_transformers import SentenceTransformer

model_name = '$model_name'
local_dir = '$local_dir'

print(f'ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: {model_name}')

try:
    # Causal LM ëª¨ë¸ ì‹œë„
    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)
    
    tokenizer.save_pretrained(local_dir)
    model.save_pretrained(local_dir)
    print(f'âœ… CausalLM ëª¨ë¸ ì €ìž¥ ì™„ë£Œ: {local_dir}')
    
except Exception as e1:
    try:
        # ì¼ë°˜ ëª¨ë¸ ì‹œë„
        tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
        model = AutoModel.from_pretrained(model_name, trust_remote_code=True)
        
        tokenizer.save_pretrained(local_dir)
        model.save_pretrained(local_dir)
        print(f'âœ… ì¼ë°˜ ëª¨ë¸ ì €ìž¥ ì™„ë£Œ: {local_dir}')
        
    except Exception as e2:
        try:
            # Sentence Transformer ì‹œë„
            model = SentenceTransformer(model_name)
            model.save(local_dir)
            print(f'âœ… SentenceTransformer ëª¨ë¸ ì €ìž¥ ì™„ë£Œ: {local_dir}')
            
        except Exception as e3:
            print(f'âŒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {model_name}')
            print(f'   CausalLM ì˜¤ë¥˜: {e1}')
            print(f'   ì¼ë°˜ ëª¨ë¸ ì˜¤ë¥˜: {e2}')
            print(f'   SentenceTransformer ì˜¤ë¥˜: {e3}')
"
}

# 1. í•œêµ­ì–´ íŠ¹í™” ê²½ëŸ‰ ëª¨ë¸ (í•„ìˆ˜)
download_hf_model "beomi/KcELECTRA-base-v2022" "kcelectra-base"
download_hf_model "klue/roberta-base" "klue-roberta"

# 2. ë‹¤êµ­ì–´ ìž„ë² ë”© ëª¨ë¸
download_hf_model "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2" "multilingual-minilm"

# 3. ê²½ëŸ‰ ìƒì„± ëª¨ë¸ (ì„ íƒì‚¬í•­ - ìš©ëŸ‰ ê³ ë ¤)
echo "âš ï¸  ëŒ€ìš©ëŸ‰ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œìž‘ (ì„ íƒì‚¬í•­)"
echo "   ìŠ¤í‚µí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš” (10ì´ˆ ëŒ€ê¸°)"
sleep 10

download_hf_model "microsoft/DialoGPT-medium" "dialogpt-medium"

# 4. spaCy í•œêµ­ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
echo "ðŸ“š spaCy í•œêµ­ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"
python3 -m spacy download ko_core_news_sm
python3 -m spacy download ko_core_news_md

# ëª¨ë¸ ì •ë³´ íŒŒì¼ ìƒì„±
cat > model_info.txt << EOF
# í¬í•¨ëœ ëª¨ë¸ ëª©ë¡
- kcelectra-base: í•œêµ­ì–´ ELECTRA ëª¨ë¸ (PII íƒì§€ìš©)
- klue-roberta: í•œêµ­ì–´ RoBERTa ëª¨ë¸ (NERìš©)
- multilingual-minilm: ë‹¤êµ­ì–´ ìž„ë² ë”© ëª¨ë¸
- dialogpt-medium: ëŒ€í™” ìƒì„± ëª¨ë¸ (ì„ íƒì‚¬í•­)
- ko_core_news_sm: spaCy í•œêµ­ì–´ ì†Œí˜• ëª¨ë¸
- ko_core_news_md: spaCy í•œêµ­ì–´ ì¤‘í˜• ëª¨ë¸

ë‹¤ìš´ë¡œë“œ ë‚ ì§œ: $(date)
ì „ì²´ ìš©ëŸ‰: $(du -sh . | cut -f1)
EOF

echo "âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!"
echo "ðŸ“ ëª¨ë¸ ì €ìž¥ ìœ„ì¹˜: $(pwd)"
echo "ðŸ“Š ì „ì²´ ìš©ëŸ‰: $(du -sh . | cut -f1)"

cd ..